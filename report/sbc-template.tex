\documentclass[12pt]{article}

\usepackage{sbc-template}


%\usepackage[latin1]{inputenc}  
%\usepackage[utf8]{inputenc}  

\usepackage{graphicx,url}
\usepackage[brazil]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{float}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage[export]{adjustbox}
\usepackage[portuguese,noend,ruled]{algorithm2e}

\sloppy

\title{IAR0001 - 2017/1\\Relatório Trabalho 4\\3-CNF-SAT com Simulated Annealing}

\author{Alexandre Maros\inst{1} }

\address{Departamento de Ciência da Computação -- Universidade do Estado de Santa Catarina\\
  Centro de Ciências Tecnológicas -- Joinville -- SC -- Brasil
  \email{alehstk@gmail.com}
}

\begin{document} 

\maketitle

%\begin{abstract}
    %Abstract
%\end{abstract}
     
\begin{resumo} 
    Este artigo apresentará o conceito de algoritmos de melhorias iterativas e estudará
    o comportamento do algoritmo \textit{Simualated Annealing} sobre o problema 3-CNF-SAT,
    comparando-o com um algoritmo de busca aleatória.
\end{resumo}

% 1. Introdução
%   Contextualização do problema, justificativa, objetivos, estrutura do relatório.
\section{Introdução}

Uma das formas de se encontrar uma solução para um problema é utilizando o algoritmos
de melhorias iterativas. A ideia principal é começar com um estado inicial, que é uma
solução completa do problema, e melhorá-lo iterativamente no decorrer do algoritmo.
Problemas que podem ser resolvidos com essa técnica geralmente são classificados
como problemas de otimização.

Um exemplo de melhoria iterativa é o algoritmo de \textbf{\textit{Hill-Climbing}}, ou
Subida da Encosta. Esse algoritmo pode ser resumido em um \textit{loop} que fica se movendo
na direção que está crescendo. Em outras palavras, é um \textit{loop} que gera uma solução
perturbando a solução atual e verifica se aquela solução é melhor que a atual, caso contrário
esta solução é descartada e outra é gerada.

Essa abordam apresenta alguns problemas. O principal são os máximos locais. O algoritmo
pode atingir um máximo local e achar que é a melhor solução, deixando de encontrar o
máximo global. Outro problema são os platôs, onde o algoritmo pode achar que chegou em
uma solução que não pode ser melhorada e retornar a solução atual.

Uma outra abordagem para os problemas de otimização é o algoritmo de \textit{\textbf{Simulated Annealing}},
uma técnica que veio a partir de observações do cozimento de vidros e metais da metalurgia
e combina buscas globais com buscas locais.

Para modificar a forma de um metal, ele primeiro é aquecido a uma altíssima temperatura.
Quanto maior sua temperatura, mais maleável ele se torna, podendo assumir diversas formas. Conforme
a temperatura diminui, ele se torna mais resistente as mudanças.
No \textit{\textbf{Simulated Annealing}} a ideia é a mesma. O algoritmo começa com
uma variável de temperatura. Quando essa temperatura está alta, soluções piores são
mais suscetíveis a serem aceitas (o algoritmo pode estar em um máximo local, logo
buscar outros lugares se torna interessante). Quanto menor a temperatura, menos chances
tem de uma solução pior ser aceita. A variação da temperatura pode ser controlada a partir
de uma função de mapeamento, que toma como parâmetro as iterações desejáveis do
algoritmo \cite{Russell:2009:AIM:1671238}.

% 2. Problemática
%   Detalhamento do problema, PEAS e características do problema
\section{Problemática}

O problema a ser resolvido aqui é o SAT, ou Problema de Satisfabilidade Booleana,
mais especificamente o problema 3-CNF-SAT.

O Problema de Satisfabilidade Booleana consiste em buscar uma determinada interpretação
lógica capaz de satisfazer um conjunto de proposições booleanas. A forma normal
conjuntiva (\textit{Conjunctive Normal Form}, CNF) é uma conjunção de cláusulas onde
cada cláusula é uma disjunção de literais. Em outras palavras, é um aglomerado de cláusulas
ligadas pelo operador lógico \textit{and} ($\land$) onde cada cláusula tem literais ligados
pelo operador \textit{or} ($\lor$). O ``3'' quer dizer que cada cláusula deve ter exatamente
3 literais, como por exemplo: $(x_1 \lor \neg x_2 \lor x_3) \land (\neg x_1 \lor x_4 \lor x_5)$.

Os problemas foram retirados do \textit{SATLIB -- Benchmark Problems} da \textit{University
of British Columbia}\footnote{Disponível em: http://www.cs.ubc.ca/~hoos/SATLIB/benchm.html}.
A Tabela~\ref{tab:prob} mostra as instância utilizadas nos testes junto com a quantidade de variáveis
e cláusulas.

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \toprule
        \text{Instância} & \text{Número de Variáveis} & \text{Número de Cláusulas} \\
        \midrule
        uf20-01 & 20 & 91 \\
        uf100-01 & 100 & 430 \\
        uf250-01 & 250 & 1065 \\
        \bottomrule
    \end{tabular}
    \caption{Instâncias utilizadas}\label{tab:prob}
\end{table}

% 3. Modelo implementado
%   Estratégias utilizadas, fórmulas, definições de implementação, linguagem
\section{Modelo implementado}

Para resolver a problemática proposta, o algoritmo de \textit{\textbf{Simulated Annealing}} será
utilizado. Como comentado na introdução do algoritmo, ha algumas informações necessárias
a serem definidas: a temperatura inicial e final, como o resfriamento ocorre, como a perturbação
da solução é feita e qual a condição de parada.

\subsection{Temperatura}

A temperatura é uma variável que deve ser definida através de experimentações. As
temperaturas que foram definidas após alguns casos de teste foram as seguintes:

\begin{itemize}
    \item Temperatura Inicial: 5
    \item Temperature Final: 0
\end{itemize}

\subsection{Resfriamento}

A função de resfriamento escolhida foi proposta por Brian T. Luke\footnote{Disponível em: http://www.btluke.com/simanf1.html}
e é descrita pela seguinte equação:

\begin{equation}
    T_i = \dfrac{1}{2} (T_0 - T_N) (1 + \mathlarger{cos(}\dfrac{i \pi}{N}\mathlarger{)}) + T_n,
\end{equation}

onde $T_i$ é a tempretura na iteração $i$, $T_0$ é a temperatura inicial, $T_N$ a
temperatura final, $i$ a iteração e $N$ a quantidade máxima de iterações.
Assumindo as temperaturas definidas anterioramente e 500 mil iterações, pode-se observar
como o decaimento se comporta na Figura~\ref{fig:temp}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/temperatura}
    \caption{Função de Resfriamento}
    \label{fig:temp}
\end{figure}

\subsection{Perturbação e condição de aceitação}

Para buscar uma melhor solução que a atual é necessário realizar uma perturbação.
Neste trabalha a função de perturbação percorre o vetor das variáveis lógicas e para
cada variável ele faz um \textit{bitflip} com uma chance de 5\%. Dada essa nova solução
ele checa se a solução perturbada é melhor que a atual, caso seja ele aceita a nova
solução automaticamente, caso contrário ele aceita a nova solução com a seguinte probabilidade:

\begin{equation}
    \mathlarger{p = e}^{\dfrac{\Delta E}{t_i}},
\end{equation}

onde $p$ é a probabilidade de aceitação $\Delta E$ a diferença entre a energia (quantidade
de cláusulas marcadas como verdadeiras) da próxima solução menos a energia da solução atual, e
$t_i$ a temperatura atual.

\subsection{Condição de parada}

A condição de parada está atrelada a quantidade de iterações que o sistema irá executar.
Neste trabalho foram especificadas 500 mil iterações.

\section{Experimentos e análises}

Para haver uma comparação a problemática aqui descrita também foi executada sobre um
algoritmo de busca aleatória. Como o nome diz, a cada iteração o algoritmo gera uma
solução aleatória, caso seja melhor que a anterior ele aceita, do contrário, rejeita. 
A Tabela~\ref{tab:tab1} mostra os resultados de ambos os algoritmo após 500 mil iterações
e 10 execuções.

\begin{table}[h]
    \centering
    \begin{tabular}{lSSSSSS}
        \toprule
        \multirow{2}{*}{Instância} &
            \multicolumn{2}{c}{Simulated Annealing} &
            \multicolumn{2}{c}{Busca Aleatória} \\
            & {$\bar{x}$} & {$\sigma$} & {$\bar{x}$} & {$\sigma$} \\
            \midrule
        uf20-01 & 91 & 0 & 90 & 0 \\
        uf100-01 & 427.9 & 0.567 & 402.7 & 1.828 \\
        uf250-01 & 1036.5 & 3.027 & 978.5 & 1.433 \\
        \bottomrule
  \end{tabular}
  \caption{Resultados obtidos}\label{tab:tab1}
\end{table}

Como nota-se na tabela, o algoritmo de Simulated Annealing atingiu um resultado
melhor nas três instancias. As Figuras~\ref{fig:uf20},~\ref{fig:uf100}~e~\ref{fig:uf250}
mostram a média das soluções das 10 execuções a cada iteração.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/20_t5_cs5}
    \caption{Instância uf20-01}
    \label{fig:uf20}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/100_t5_cs5}
    \caption{Instância uf100-01}
    \label{fig:uf100}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figuras/250_t5_cs5}
    \caption{Instância uf250-01}
    \label{fig:uf250}
\end{figure}

Os gráficos demonstram como a temperatura afeta a convergência do problema. No inicio,
quando a temperatura ainda é alta, temos um comportamento parecido com o da busca
aleatória. Conforme a temperatura vai decaindo, a busca começa a ser mais localizada,
aceitando soluções com menos variações que a atual. No final, o algoritmo passa a
aceitar somente resultados melhores que o atual, imitando uma busca gulosa.

\clearpage

%\begin{table}[h]
    %\centering
    %\begin{tabular}{lSSSSSS}
        %\toprule
        %\multirow{2}{*}{Instância} &
            %\multicolumn{2}{c}{Simulated Annealing} &
            %\multicolumn{2}{c}{Random Search} \\
            %& {$\bar{x}$} & {$\sigma$} & {$\bar{x}$} & {$\sigma$} \\
            %\midrule
        %uf20-01 & 91 & 0 & 90 & 0 \\
        %uf100-01 & 430 & 0 & 402.7 & 1.828 \\
        %uf250-01 & 1064.3 & 1.059 & 978.5 & 1.433 \\
        %\bottomrule
  %\end{tabular}
  %\caption{Resultados obtidos}\label{tab:tab1}
%\end{table}

% 5. Conclusão
%   Considerações sobre o trabalho e sobre os resultados obtidos, trabalhos futuros.
\section{Conclusão}

O algoritmo de \textit{\textbf{Simulated Annealing}} provou ser mais eficiente que o
da busca aleatória. O comportamento de convergência é uma interessante propriedade que
pode ser utilizada por diversos problemas de otimização.

Como trabalho futuro, resta estudar a mudança de comportamento que diferentes
funções de esfriamento tem, melhor identificar as temperaturas inciais e finais
e comparar o algoritmo estudado com outros algoritmos de otimização, como os algoritmos
genéticos.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
